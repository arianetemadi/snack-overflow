{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>ratio_func_words</th>\n",
       "      <th>ratio_unique_pos</th>\n",
       "      <th>length</th>\n",
       "      <th>pos_repetitions</th>\n",
       "      <th>ratio_noun</th>\n",
       "      <th>ratio_verb</th>\n",
       "      <th>ratio_adj</th>\n",
       "      <th>ratio_adv</th>\n",
       "      <th>ratio_pron</th>\n",
       "      <th>ratio_propn</th>\n",
       "      <th>syntactic_depth</th>\n",
       "      <th>branching_factor</th>\n",
       "      <th>reversed_probability</th>\n",
       "      <th>average_surprisingness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.922017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>6</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.849506</td>\n",
       "      <td>0.977015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.805611</td>\n",
       "      <td>0.961821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>0.873509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "   ratio_func_words  ratio_unique_pos  length  pos_repetitions  ratio_noun  \\\n",
       "0          0.125000          0.625000       8                1    0.500000   \n",
       "1          0.266667          0.600000      15                1    0.133333   \n",
       "2          0.125000          0.875000       8                0    0.250000   \n",
       "3          0.250000          0.500000       8                1    0.375000   \n",
       "4          0.272727          0.454545      11                1    0.181818   \n",
       "\n",
       "   ratio_verb  ratio_adj  ratio_adv  ratio_pron  ratio_propn  syntactic_depth  \\\n",
       "0    0.125000   0.125000   0.000000       0.000     0.125000                5   \n",
       "1    0.133333   0.133333   0.066667       0.000     0.266667                6   \n",
       "2    0.125000   0.125000   0.125000       0.125     0.000000                4   \n",
       "3    0.375000   0.000000   0.000000       0.000     0.000000                6   \n",
       "4    0.272727   0.000000   0.272727       0.000     0.000000                6   \n",
       "\n",
       "   branching_factor  reversed_probability  average_surprisingness  \n",
       "0          1.400000              0.289101                0.922017  \n",
       "1          2.800000              0.849506                0.977015  \n",
       "2          1.750000              0.135305                0.887056  \n",
       "3          1.166667              0.805611                0.961821  \n",
       "4          2.000000              0.458575                0.873509  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   is_sarcastic            28619 non-null  int64  \n",
      " 1   headline                28619 non-null  object \n",
      " 2   ratio_func_words        28619 non-null  float64\n",
      " 3   ratio_unique_pos        28619 non-null  float64\n",
      " 4   length                  28619 non-null  int64  \n",
      " 5   pos_repetitions         28619 non-null  int64  \n",
      " 6   ratio_noun              28619 non-null  float64\n",
      " 7   ratio_verb              28619 non-null  float64\n",
      " 8   ratio_adj               28619 non-null  float64\n",
      " 9   ratio_adv               28619 non-null  float64\n",
      " 10  ratio_pron              28619 non-null  float64\n",
      " 11  ratio_propn             28619 non-null  float64\n",
      " 12  syntactic_depth         28619 non-null  int64  \n",
      " 13  branching_factor        28619 non-null  float64\n",
      " 14  reversed_probability    28619 non-null  float64\n",
      " 15  average_surprisingness  28619 non-null  float64\n",
      "dtypes: float64(11), int64(4), object(1)\n",
      "memory usage: 3.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Path to the JSON file\n",
    "file_path = r\"C:\\Users\\MSC\\OneDrive - Fraunhofer Austria Research GmbH\\Desktop\\NLP\\data\\trans_prob_temp.csv\"\n",
    "\n",
    "# Reading the JSON file into a DataFrame\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()  # Display the first few rows of the DataFrame\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = data.drop(columns=['pos_tags', 'syntax_tree'])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "display(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.iloc[:, 1:]  # Columns 4-17\n",
    "y = data['is_sarcastic']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "SEED = 42\n",
    "train_headlines, other_headlines = split(data, test_size=0.3, random_state=SEED)  # 70% training\n",
    "val_headlines, test_headlines = split(other_headlines, test_size=0.5, random_state=SEED)  # 15% validation, 15% test\n",
    "\n",
    "# Prepare data for the Logistic Regression model\n",
    "# Extract the corresponding feature values for train, validation, and test\n",
    "X_train = X.loc[train_headlines.index]\n",
    "y_train = y.loc[train_headlines.index]\n",
    "X_val = X.loc[val_headlines.index]\n",
    "y_val = y.loc[val_headlines.index]\n",
    "X_test = X.loc[test_headlines.index]\n",
    "y_test = y.loc[test_headlines.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores:\n",
      "                         ANOVA_F       RFE  RandomForest  Average_Score\n",
      "ratio_func_words        1.000000  1.000000      0.800903       0.933634\n",
      "ratio_unique_pos        0.365082  1.000000      0.557736       0.640939\n",
      "ratio_verb              0.556911  1.000000      0.561078       0.705996\n",
      "ratio_adv               0.276317  1.000000      0.232271       0.502862\n",
      "ratio_pron              0.142221  1.000000      0.176568       0.439596\n",
      "ratio_propn             0.145956  0.444444      0.392269       0.327556\n",
      "ratio_adj               0.104327  0.259259      0.319761       0.227783\n",
      "average_surprisingness  0.034888  0.166667      1.000000       0.400518\n",
      "branching_factor        0.423827  0.111111      0.535848       0.356929\n",
      "reversed_probability    0.000000  0.074074      0.985165       0.353080\n",
      "ratio_noun              0.292966  0.047619      0.470016       0.270200\n",
      "syntactic_depth         0.286037  0.027778      0.307704       0.207173\n",
      "pos_repetitions         0.008487  0.012346      0.000000       0.006944\n",
      "length                  0.012050  0.000000      0.222846       0.078299\n",
      "Selected Features: ['ratio_func_words', 'ratio_unique_pos', 'ratio_verb', 'ratio_adv', 'ratio_pron', 'ratio_propn', 'ratio_adj', 'average_surprisingness', 'branching_factor', 'reversed_probability']\n"
     ]
    }
   ],
   "source": [
    "synX = X.drop(columns=['headline'])\n",
    "\n",
    "# 1. Filter Method: Univariate Statistical Test (ANOVA F-test)\n",
    "select_k_best = SelectKBest(score_func=f_classif, k='all')\n",
    "anova_scores = select_k_best.fit(synX, y).scores_\n",
    "\n",
    "# 2. Wrapper Method: Recursive Feature Elimination (RFE) with Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=log_model, n_features_to_select=5)  # Select top 5 features\n",
    "rfe.fit(synX, y)\n",
    "rfe_ranks = rfe.ranking_\n",
    "\n",
    "# 3. Embedded Method: Feature Importance from Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(synX, y)\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale each method's scores to [0, 1]\n",
    "anova_scaled = scaler.fit_transform(anova_scores.reshape(-1, 1)).flatten()\n",
    "rfe_scaled = scaler.fit_transform((1 / rfe_ranks).reshape(-1, 1)).flatten()  # Inverse for ranking\n",
    "rf_scaled = scaler.fit_transform(rf_importances.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Combine the scores into a DataFrame\n",
    "feature_scores = {\n",
    "    'ANOVA_F': anova_scaled,\n",
    "    'RFE': rfe_scaled,\n",
    "    'RandomForest': rf_scaled\n",
    "}\n",
    "importance_df = pd.DataFrame(feature_scores, index=synX.columns)\n",
    "\n",
    "# Add an average score column\n",
    "importance_df['Average_Score'] = importance_df.mean(axis=1)\n",
    "importance_df = importance_df.sort_values(by='RFE', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Scores:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Select features based on average score threshold\n",
    "selected_features = importance_df[importance_df['RFE'] > 0.05].index.tolist()\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# # Keep only selected features\n",
    "# X_selected = X[selected_features]\n",
    "\n",
    "# # Updated dataset with selected features and headlines\n",
    "# data_transformed = pd.concat([data[['is_sarcastic', 'headline']], X_selected], axis=1)\n",
    "# print(\"Transformed DataFrame:\")\n",
    "# print(data_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(X_train, importance_df, method):\n",
    "    \"\"\"\n",
    "    Returns the X data (including the headlines) that contains the top 5 syntactic features\n",
    "    based on the specified feature selection method.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): The training data including headlines.\n",
    "    importance_df (pd.DataFrame): DataFrame containing feature importance scores.\n",
    "    method (str): The feature selection method ('ANOVA_F', 'RFE', 'RandomForest').\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the top 5 syntactic features and headlines.\n",
    "    \"\"\"\n",
    "    if method not in importance_df.columns:\n",
    "        raise ValueError(f\"Method {method} not found in importance_df columns.\")\n",
    "    \n",
    "    # Select the top 5 features based on the specified method\n",
    "    top_features = importance_df.nlargest(5, method).index.tolist()\n",
    "    \n",
    "    # Include the 'headline' column\n",
    "    top_features_with_headline = ['headline'] + top_features\n",
    "    \n",
    "    # Return the X data with the selected features\n",
    "    return X_train[top_features_with_headline]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                headline  \\\n",
      "12170  american express to offer 5 months of paternit...   \n",
      "28552  watch: dolphin knocks stand-up paddleboarder o...   \n",
      "6883           man who enjoys thing informed he is wrong   \n",
      "28387  jonathan lipnicki to star as young 'dark helme...   \n",
      "12932  publicist worried kanye west's support of trum...   \n",
      "\n",
      "       average_surprisingness  reversed_probability  ratio_func_words  \\\n",
      "12170                0.870541              0.185371          0.272727   \n",
      "28552                0.927349              0.517047          0.363636   \n",
      "6883                 0.981490              0.879098          0.125000   \n",
      "28387                0.921614              0.301929          0.384615   \n",
      "12932                0.808175              0.004917          0.272727   \n",
      "\n",
      "       ratio_verb  ratio_unique_pos  \n",
      "12170    0.272727          0.636364  \n",
      "28552    0.272727          0.545455  \n",
      "6883     0.250000          0.625000  \n",
      "28387    0.153846          0.538462  \n",
      "12932    0.181818          0.500000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "top_features_df = get_top_features(X_train, importance_df, 'RandomForest')\n",
    "print(top_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
