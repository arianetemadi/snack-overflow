{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.VotingClassifier import VotingClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier with validation data   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier with Validation Data\n",
    "\n",
    "In this notebook, we train a Voting Classifier and evaluate its performance on various datasets. The `VotingClassifier` implements majority hard voting between three models:\n",
    "\n",
    "1. **Naive Bayes Baseline**\n",
    "2. **Logistic Regression Model (Syntactic)**\n",
    "3. **Random Forest Model (Syntactic)**\n",
    "\n",
    "### Benefits of the Voting Classifier\n",
    "\n",
    "The Voting Classifier combines the predictions of multiple models to improve overall performance. Here are some potential benefits:\n",
    "\n",
    "- **Improved Accuracy**: By aggregating the predictions of different models, the Voting Classifier can achieve higher accuracy compared to individual models.\n",
    "- **Robustness**: The combination of different models can make the classifier more robust to overfitting and noise in the data.\n",
    "- **Reduced Bias**: Each model may have its own biases, but combining them can help to balance these biases, leading to more reliable predictions.\n",
    "- **Flexibility**: The Voting Classifier can be easily extended to include additional models, making it a flexible choice for various tasks.\n",
    "\n",
    "By leveraging the strengths of multiple models, the Voting Classifier aims to provide a more accurate and reliable classification system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20033/20033 [00:34<00:00, 573.87it/s]\n",
      "100%|██████████| 4293/4293 [00:02<00:00, 2043.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85      2218\n",
      "           1       0.85      0.81      0.83      2075\n",
      "\n",
      "    accuracy                           0.84      4293\n",
      "   macro avg       0.84      0.84      0.84      4293\n",
      "weighted avg       0.84      0.84      0.84      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1918  300]\n",
      " [ 394 1681]]\n",
      "Evaluating logistic_regression_syn_lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      2218\n",
      "           1       0.66      0.62      0.64      2075\n",
      "\n",
      "    accuracy                           0.66      4293\n",
      "   macro avg       0.66      0.66      0.66      4293\n",
      "weighted avg       0.66      0.66      0.66      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1553  665]\n",
      " [ 798 1277]]\n",
      "Evaluating random_forest_syn_rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      2218\n",
      "           1       0.62      0.62      0.62      2075\n",
      "\n",
      "    accuracy                           0.63      4293\n",
      "   macro avg       0.63      0.63      0.63      4293\n",
      "weighted avg       0.63      0.63      0.63      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1411  807]\n",
      " [ 784 1291]]\n"
     ]
    }
   ],
   "source": [
    "classifier = VotingClassifier(conllu_path=\"../data/headline_data/headlines.conllu\",\n",
    " csv_path=\"../data/headline_data/headlines_syntactic_features.csv\")\n",
    "\n",
    "classifier.fit_modles()\n",
    "classifier.predict()\n",
    "classifier.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75      2218\n",
      "           1       0.74      0.71      0.72      2075\n",
      "\n",
      "    accuracy                           0.74      4293\n",
      "   macro avg       0.74      0.74      0.74      4293\n",
      "weighted avg       0.74      0.74      0.74      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1698  520]\n",
      " [ 604 1471]]\n"
     ]
    }
   ],
   "source": [
    "classifier.voting()\n",
    "classifier.eval_voting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier with Tweets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20033/20033 [00:40<00:00, 493.57it/s]\n",
      "100%|██████████| 3468/3468 [00:01<00:00, 2037.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.80      2601\n",
      "           1       0.27      0.17      0.21       867\n",
      "\n",
      "    accuracy                           0.68      3468\n",
      "   macro avg       0.51      0.51      0.50      3468\n",
      "weighted avg       0.63      0.68      0.65      3468\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2196  405]\n",
      " [ 720  147]]\n",
      "Evaluating logistic_regression_syn_lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70      2601\n",
      "           1       0.25      0.35      0.29       867\n",
      "\n",
      "    accuracy                           0.57      3468\n",
      "   macro avg       0.50      0.50      0.49      3468\n",
      "weighted avg       0.62      0.57      0.59      3468\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1690  911]\n",
      " [ 565  302]]\n",
      "Evaluating random_forest_syn_rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.46      0.57      2601\n",
      "           1       0.25      0.54      0.34       867\n",
      "\n",
      "    accuracy                           0.48      3468\n",
      "   macro avg       0.50      0.50      0.45      3468\n",
      "weighted avg       0.62      0.48      0.51      3468\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1185 1416]\n",
      " [ 401  466]]\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"../data/tweets_data/tweets.conllu\", \"../data/tweets_data/tweets_syntactic_features.csv\"]\n",
    "\n",
    "classifier = VotingClassifier()\n",
    "classifier.fit_modles()\n",
    "classifier.predict(new_data=new_data)\n",
    "classifier.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      2601\n",
      "           1       0.25      0.33      0.28       867\n",
      "\n",
      "    accuracy                           0.58      3468\n",
      "   macro avg       0.50      0.50      0.49      3468\n",
      "weighted avg       0.62      0.58      0.60      3468\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1737  864]\n",
      " [ 583  284]]\n"
     ]
    }
   ],
   "source": [
    "classifier.voting()\n",
    "classifier.eval_voting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier with Onion-like ChatGPT Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1020/1020 [00:00<00:00, 2992.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       510\n",
      "           1       0.95      0.88      0.92       510\n",
      "\n",
      "    accuracy                           0.92      1020\n",
      "   macro avg       0.92      0.92      0.92      1020\n",
      "weighted avg       0.92      0.92      0.92      1020\n",
      "\n",
      "Confusion Matrix:\n",
      "[[488  22]\n",
      " [ 59 451]]\n",
      "Evaluating logistic_regression_syn_lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       510\n",
      "           1       0.86      0.76      0.81       510\n",
      "\n",
      "    accuracy                           0.82      1020\n",
      "   macro avg       0.83      0.82      0.82      1020\n",
      "weighted avg       0.83      0.82      0.82      1020\n",
      "\n",
      "Confusion Matrix:\n",
      "[[449  61]\n",
      " [122 388]]\n",
      "Evaluating random_forest_syn_rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73       510\n",
      "           1       0.74      0.64      0.68       510\n",
      "\n",
      "    accuracy                           0.71      1020\n",
      "   macro avg       0.71      0.71      0.71      1020\n",
      "weighted avg       0.71      0.71      0.71      1020\n",
      "\n",
      "Confusion Matrix:\n",
      "[[397 113]\n",
      " [186 324]]\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.conllu\",\n",
    "             \"../data/chatgpt_onionstyle_data/chatgpt_onionstyl_syntactic_features.csv\"]\n",
    "\n",
    "#classifier = VotingClassifier()\n",
    "#classifier.fit_modles()\n",
    "classifier.predict(new_data=new_data)\n",
    "classifier.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       510\n",
      "           1       0.91      0.82      0.86       510\n",
      "\n",
      "    accuracy                           0.87      1020\n",
      "   macro avg       0.87      0.87      0.87      1020\n",
      "weighted avg       0.87      0.87      0.87      1020\n",
      "\n",
      "Confusion Matrix:\n",
      "[[470  40]\n",
      " [ 92 418]]\n"
     ]
    }
   ],
   "source": [
    "classifier.voting()\n",
    "classifier.eval_voting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier with generic sarcastic headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2710.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       500\n",
      "           1       0.71      0.74      0.73       500\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.72      0.72      0.72      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353 147]\n",
      " [132 368]]\n",
      "Evaluating logistic_regression_syn_lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       500\n",
      "           1       0.65      0.69      0.67       500\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.66      0.66      0.66      1000\n",
      "weighted avg       0.66      0.66      0.66      1000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[310 190]\n",
      " [154 346]]\n",
      "Evaluating random_forest_syn_rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59       500\n",
      "           1       0.60      0.62      0.61       500\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.60      0.60      0.60      1000\n",
      "weighted avg       0.60      0.60      0.60      1000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[289 211]\n",
      " [190 310]]\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"../data/chatgpt_generic_data/chatgpt_generic.conllu\",\n",
    "             \"../data/chatgpt_generic_data/chatgpt_generic_syntactic_features.csv\",]\n",
    "\n",
    "#classifier = VotingClassifier()\n",
    "#classifier.fit_modles()\n",
    "classifier.predict(new_data=new_data)\n",
    "classifier.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67       500\n",
      "           1       0.67      0.73      0.70       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.68      0.68      1000\n",
      "weighted avg       0.68      0.68      0.68      1000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[317 183]\n",
      " [136 364]]\n"
     ]
    }
   ],
   "source": [
    "classifier.voting()\n",
    "classifier.eval_voting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Notebook\n",
    "\n",
    "In this notebook, we experimented with a Voting Classifier on various datasets and compared its performance against the Naive Bayes baseline. Despite our expectations, the Voting Classifier consistently performed worse than the Naive Bayes baseline. However, this outcome provides valuable insights into the behavior of our models.\n",
    "\n",
    "### Performance on Different Datasets\n",
    "\n",
    "- **Original Data**: The performance of the Voting Classifier on the original dataset was below that of the Naive Bayes baseline.\n",
    "- **ChatGPT Onion-style Headlines**: Surprisingly, the ChatGPT Onion-style headlines dataset performed even better than our original data.\n",
    "- **Tweets**: The performance on the tweets dataset was worse than the original data.\n",
    "- **Generic Headlines**: The generic headlines dataset also performed worse than the original data.\n",
    "\n",
    "### Ideas for Improving the Ensemble Classifier\n",
    "\n",
    "1. **Model Diversity**: Incorporate a more diverse set of models into the ensemble. By including models with different strengths and weaknesses, we can potentially improve the overall performance of the Voting Classifier.\n",
    "\n",
    "2. **Weighted Voting**: Implement a weighted voting mechanism where models with higher individual performance have a greater influence on the final prediction. This could help in leveraging the strengths of the better-performing models within the ensemble.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
