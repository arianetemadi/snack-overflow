{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from src.data_util import load_data\n",
    "from src.naive_bayes import NaiveBayesClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of headlines for training, validation,         and test is 20033, 4293,         and 4293 resp.\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "headlines = load_data(\"../data/dataset.conllu\")\n",
    "\n",
    "# split into training and test sets\n",
    "SEED = 42\n",
    "train_headlines, other_headlines = split(headlines, test_size=0.3, random_state=SEED)\n",
    "val_headlines, test_headlines = split(other_headlines, test_size=0.5, random_state=SEED)\n",
    "print(\n",
    "    f\"Number of headlines for training, validation, \\\n",
    "        and test is {len(train_headlines)}, {len(val_headlines)}, \\\n",
    "        and {len(test_headlines)} resp.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolsi/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "100%|██████████| 20033/20033 [04:37<00:00, 72.17it/s]\n",
      "100%|██████████| 20033/20033 [01:27<00:00, 228.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-sarcastic       1.00      1.00      1.00     10530\n",
      "    Sarcastic       1.00      1.00      1.00      9503\n",
      "\n",
      "     accuracy                           1.00     20033\n",
      "    macro avg       1.00      1.00      1.00     20033\n",
      " weighted avg       1.00      1.00      1.00     20033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4293/4293 [00:19<00:00, 224.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-sarcastic       0.84      0.89      0.86      2237\n",
      "    Sarcastic       0.87      0.81      0.84      2056\n",
      "\n",
      "     accuracy                           0.85      4293\n",
      "    macro avg       0.85      0.85      0.85      4293\n",
      " weighted avg       0.85      0.85      0.85      4293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = NaiveBayesClassifier(ngram_range=(1, 3))\n",
    "naive_bayes.fit(train_headlines)\n",
    "fp, fn = naive_bayes.test(train_headlines)\n",
    "fp, fn = naive_bayes.test(test_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the dataset\n",
    "tweets = load_data(\"../data/tweets.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sarcastic = [tweet for tweet in tweets if tweet[0].metadata['class'] == \"1\"]\n",
    "tweets_non_sarcastic = [tweet for tweet in tweets if tweet[0].metadata['class'] == \"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_sarcastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_non_sarcastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenList<The, only, thing, I, got, from, college, is, a, caffeine, addiction, metadata={text: \"The only thing I got from college is a caffeine addiction\", headline_id: \"1\", sent_id: \"0\", class: \"1\", link: \"a\"}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_non_sarcastic_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = np.random.choice(len(tweets_non_sarcastic), size=len(tweets_sarcastic), replace=False)\n",
    "for idx in sampled_indices:\n",
    "    tweets_non_sarcastic_sample.append(tweets_non_sarcastic[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tweets = tweets_sarcastic + tweets_non_sarcastic_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1734/1734 [00:10<00:00, 172.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-sarcastic       0.50      0.86      0.63       867\n",
      "    Sarcastic       0.52      0.15      0.23       867\n",
      "\n",
      "     accuracy                           0.50      1734\n",
      "    macro avg       0.51      0.50      0.43      1734\n",
      " weighted avg       0.51      0.50      0.43      1734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test on extra data\n",
    "fp, fn = naive_bayes.test(sampled_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes abseline achieved a satisfactory performance on the news headlines, however with the new dataset the metrics are significantly worse, which might suggest that we are actually not learning to detect sarcasm but rather Onion writing style vs. Huffpost writing style."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-milestone3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
