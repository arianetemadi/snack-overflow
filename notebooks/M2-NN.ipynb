{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from src.data_util import load_data\n",
    "from src.nn import BoWNN, create_dataloader_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"../data/dataset.conllu\")\n",
    "headlines = list(map(lambda line: \"\".join(list(map(lambda x: x.metadata[\"text\"], line))), data))\n",
    "labels = list(map(lambda line: int(line[0].metadata[\"class\"]), data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "X_train, other_data = split(headlines, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test = split(other_data, test_size=0.5, random_state=SEED)\n",
    "\n",
    "y_train, other_data = split(labels, test_size=0.3, random_state=SEED)\n",
    "y_val, y_test = split(other_data, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=6000)\n",
    "\n",
    "word_to_ix = vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = create_dataloader_iterator(X_train, y_train, word_to_ix, True)\n",
    "valid_iterator = create_dataloader_iterator(X_val, y_val, word_to_ix, False)\n",
    "test_iterator = create_dataloader_iterator(X_test, y_test, word_to_ix, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_nn = BoWNN(2, len(word_to_ix.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.604 | Train Prec: 85.39% | Train Rec: 75.79% | Train Fscore: 79.98%\n",
      "\t Val. Loss: 0.542 |  Val Prec: 82.60% | Val Rec: 80.74% | Val Fscore: 81.42%\n",
      "\tTrain Loss: 0.486 | Train Prec: 86.16% | Train Rec: 84.03% | Train Fscore: 84.92%\n",
      "\t Val. Loss: 0.478 |  Val Prec: 83.35% | Val Rec: 82.23% | Val Fscore: 82.59%\n",
      "\tTrain Loss: 0.428 | Train Prec: 86.94% | Train Rec: 86.11% | Train Fscore: 86.35%\n",
      "\t Val. Loss: 0.444 |  Val Prec: 83.31% | Val Rec: 82.24% | Val Fscore: 82.62%\n",
      "\tTrain Loss: 0.390 | Train Prec: 87.43% | Train Rec: 87.03% | Train Fscore: 87.09%\n",
      "\t Val. Loss: 0.423 |  Val Prec: 83.57% | Val Rec: 83.18% | Val Fscore: 83.21%\n",
      "\tTrain Loss: 0.363 | Train Prec: 87.89% | Train Rec: 88.01% | Train Fscore: 87.79%\n",
      "\t Val. Loss: 0.409 |  Val Prec: 84.10% | Val Rec: 83.08% | Val Fscore: 83.43%\n",
      "\tTrain Loss: 0.344 | Train Prec: 88.43% | Train Rec: 88.74% | Train Fscore: 88.43%\n",
      "\t Val. Loss: 0.399 |  Val Prec: 84.78% | Val Rec: 83.19% | Val Fscore: 83.82%\n",
      "\tTrain Loss: 0.328 | Train Prec: 89.40% | Train Rec: 88.90% | Train Fscore: 89.01%\n",
      "\t Val. Loss: 0.391 |  Val Prec: 83.96% | Val Rec: 84.01% | Val Fscore: 83.83%\n",
      "\tTrain Loss: 0.315 | Train Prec: 89.38% | Train Rec: 89.52% | Train Fscore: 89.30%\n",
      "\t Val. Loss: 0.386 |  Val Prec: 84.58% | Val Rec: 83.59% | Val Fscore: 83.93%\n",
      "\tTrain Loss: 0.303 | Train Prec: 89.90% | Train Rec: 89.91% | Train Fscore: 89.77%\n",
      "\t Val. Loss: 0.381 |  Val Prec: 84.99% | Val Rec: 83.53% | Val Fscore: 84.09%\n",
      "\tTrain Loss: 0.293 | Train Prec: 90.20% | Train Rec: 90.07% | Train Fscore: 90.00%\n",
      "\t Val. Loss: 0.378 |  Val Prec: 85.27% | Val Rec: 83.64% | Val Fscore: 84.28%\n",
      "\tTrain Loss: 0.284 | Train Prec: 90.69% | Train Rec: 90.28% | Train Fscore: 90.34%\n",
      "\t Val. Loss: 0.375 |  Val Prec: 84.92% | Val Rec: 83.96% | Val Fscore: 84.26%\n",
      "\tTrain Loss: 0.276 | Train Prec: 90.92% | Train Rec: 90.71% | Train Fscore: 90.68%\n",
      "\t Val. Loss: 0.374 |  Val Prec: 85.36% | Val Rec: 83.33% | Val Fscore: 84.18%\n",
      "\tTrain Loss: 0.269 | Train Prec: 91.36% | Train Rec: 90.78% | Train Fscore: 90.95%\n",
      "\t Val. Loss: 0.373 |  Val Prec: 84.79% | Val Rec: 83.34% | Val Fscore: 83.87%\n",
      "\tTrain Loss: 0.262 | Train Prec: 91.39% | Train Rec: 91.06% | Train Fscore: 91.11%\n",
      "\t Val. Loss: 0.372 |  Val Prec: 84.99% | Val Rec: 83.16% | Val Fscore: 83.88%\n",
      "\tTrain Loss: 0.256 | Train Prec: 91.72% | Train Rec: 91.30% | Train Fscore: 91.38%\n",
      "\t Val. Loss: 0.371 |  Val Prec: 84.95% | Val Rec: 83.43% | Val Fscore: 83.98%\n"
     ]
    }
   ],
   "source": [
    "bow_nn.training_loop(train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37598859935122375,\n",
       " 0.8396285533099147,\n",
       " 0.8312638111839947,\n",
       " 0.8332562719124196)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_nn.evaluate(test_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
