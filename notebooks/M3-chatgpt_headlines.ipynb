{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake headlines generated by ChatGPT\n",
    "\n",
    "We asked ChatGPT to generate headlines similar to the style of our two news sources, Onion and HuffPost.\n",
    "We gathered 510 fake headlines for each, 1020 in total. In the process of prompting, we used prompting techniques to get better performance from the model, to make sure the model itself is considering what is the style of each news source and what are their properties. And to make sure the generated headlines are diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gathered all headlines in the text file `data/chatgpt_onionstyle_data/chatgpt_onionstyle.txt`.\n",
    "Here are some examples:\n",
    "* Like Onion:\n",
    "    * local dad hopes to be remembered as the guy who never saw ‘the fast and furious’\n",
    "    * area man insists world is flat, despite never leaving his basement\n",
    "    * scientists warn new virus could spread via passive-aggressive texts\n",
    "    * area siblings finally agree to stop faking peace during family gatherings\n",
    "    * survey finds the majority of couples argue over whether to watch tv or just stare into space\n",
    "    * couple celebrates 10 years together by agreeing they still don’t know how to do the dishes\n",
    "    * report finds 68% of workplace meetings could be emails, and 32% could be screams\n",
    "    * new candle company promises scents that smell exactly like regret\n",
    "    * local dog suspiciously eyeing amazon package\n",
    "    * new gym introduces revolutionary workout where you just watch people exercise\n",
    "* Like HuffPost:\n",
    "    * how ai is quietly shaping the future of democracy\n",
    "    * this common food might be sabotaging your weight loss goals\n",
    "    * the heartwarming story of a dog who saved its owner’s life\n",
    "    * why millennials are obsessed with vintage tupperware\n",
    "    * how a group of teens built an app that’s saving lives\n",
    "    * this grandmother’s daily walks are inspiring an entire community\n",
    "    * why experts say you should declutter your mind before your closet\n",
    "    * how tech layoffs are creating new opportunities for start-ups\n",
    "    * how to stop comparing yourself to others – for good\n",
    "    * this single mom’s side hustle turned into a $1 million business\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our opinion, ChatGPT did a reasonable job at faking headlines of these two sources.\n",
    "Many fake headlines for Onion are genuinely funny with a dead-pan tone, and many fake headlines imitating HuffPost are serious, inspirational, and practical.\n",
    "Each seems to follow the style of its respective source.\n",
    "\n",
    "Now let's analyze..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from src.preprocessing import convert_txt_to_json, convert_to_conllu\n",
    "from src.data_util import load_data\n",
    "from src.naive_bayes import NaiveBayesClassifier\n",
    "from src.patterns import fit_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert the data to the conllu format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1020/1020 [00:08<00:00, 116.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert txt file to JSON file\n",
    "input_file = \"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.txt\"\n",
    "output_file = \"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.json\"\n",
    "convert_txt_to_json(\n",
    "    input_file=input_file, output_file=output_file, link=\"https://chatgpt.com/\"\n",
    ")\n",
    "\n",
    "# convert JSON file to conllu dataset\n",
    "output_file = \"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.conllu\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "file_path = \"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.json\"\n",
    "data = pd.read_json(file_path, lines=True)\n",
    "convert_to_conllu(data, output_file, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test our Naive Bayes Bag of Words model on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of headlines for training, testing,         and testing fake headlines is 20033, 4293,         and 1020 resp.\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "headlines = load_data(\"../data/headline_data/headlines.conllu\")\n",
    "fake_headlines = load_data(\"../data/chatgpt_onionstyle_data/chatgpt_onionstyle.conllu\")\n",
    "\n",
    "# split into training and test sets\n",
    "SEED = 42\n",
    "train_headlines, other_headlines = split(headlines, test_size=0.3, random_state=SEED)\n",
    "_, test_headlines = split(other_headlines, test_size=0.5, random_state=SEED)\n",
    "print(\n",
    "    f\"Number of headlines for training, testing, \\\n",
    "        and testing fake headlines is {len(train_headlines)}, {len(test_headlines)}, \\\n",
    "        and {len(fake_headlines)} resp.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arian/projects/snack-overflow/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "100%|██████████| 20033/20033 [00:23<00:00, 850.41it/s] \n"
     ]
    }
   ],
   "source": [
    "# fit the Naive Bayes Bag of Word model to training data\n",
    "naive_bayes = NaiveBayesClassifier(ngram_range=(1, 1))\n",
    "naive_bayes.fit(train_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4293/4293 [00:01<00:00, 3103.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-sarcastic       0.84      0.86      0.85      2237\n",
      "    Sarcastic       0.84      0.82      0.83      2056\n",
      "\n",
      "     accuracy                           0.84      4293\n",
      "    macro avg       0.84      0.84      0.84      4293\n",
      " weighted avg       0.84      0.84      0.84      4293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test on test data (of the original dataset, not fake)\n",
    "_, _ = naive_bayes.test(test_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1020/1020 [00:00<00:00, 3137.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-sarcastic       0.89      0.95      0.92       510\n",
      "    Sarcastic       0.95      0.89      0.92       510\n",
      "\n",
      "     accuracy                           0.92      1020\n",
      "    macro avg       0.92      0.92      0.92      1020\n",
      " weighted avg       0.92      0.92      0.92      1020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# now test on fake headlines generated by ChatGPT and get false positive and negatives\n",
    "fp, fn = naive_bayes.test(fake_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, our model that is trained on the original dataset, performs very well on classifying these fake headlines generated by ChatGPT.\n",
    "In fact, it reaches a much higher value for all three metrics (precision, recall, and f1-score) on both classes than it had for our actual test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe this is because ChatGPT is utilizing the most common patterns of each source too much when generating fake headlines.\n",
    "Consider some familiar patterns by Onion, the ones that include expressions like\n",
    "* local man...\n",
    "* nation believes...\n",
    "* study shows...\n",
    "\n",
    "These patterns are abundant in Onion headlines.\n",
    "But by taking a look at the datasets, it becomes clear that ChatGPT is using these patterns too much.\n",
    "The same is true for some familiar patterns used by HuffPost:\n",
    "* how...\n",
    "* why...\n",
    "* here's..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's confirm these hypotheses by running some patterns on each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns =  [\n",
    "    \".*area man.*\",\n",
    "    \".*nation.*\",\n",
    "    \".*local.*\",\n",
    "    \".*study.*\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class = 1: precision=0.7926267281105991, recall=0.08365758754863813\n",
      "-- examples that fit these patterns: \n",
      "bigot annoyed local mosque already vandalized before he got there\n",
      "study finds over 5 million birds die annually from head-on collisions with clouds\n",
      "area man may have lied about having sex\n",
      "study: american spiritual epiphanies increasingly juice-based\n",
      "white nationalists have been saying 'diversity is not our strength' for years\n",
      "local welder suffering from welder's block\n",
      "guy from sopranos drops by local pizza parlor for free slice\n",
      "government shutdown forces national zoo to turn off panda suicide cam\n",
      "you can't study college coaches without looking at the players\n",
      "study exposes risks of conducting research while driving\n"
     ]
    }
   ],
   "source": [
    "_ = fit_patterns(test_headlines, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class = 1: precision=0.9408866995073891, recall=0.37450980392156863\n",
      "-- examples that fit these patterns: \n",
      "area man starts company that specializes in making people feel uncomfortable on zoom\n",
      "study finds majority of bees too busy to explain how pollination works\n",
      "local cat declares war on ceiling fan, promises total victory\n",
      "nation’s weathermen announce bold new plan to blame every wrong forecast on wind\n",
      "study finds most horoscopes just general enough to be creepy\n",
      "local man feels profound sense of accomplishment after completing a single task\n",
      "local museum announces new exhibit: the history of museum announcements\n",
      "area man announces he’s not watching tv, just resting his eyes on the screen\n",
      "local influencer claims moral high ground after liking charity post first\n",
      "nation agrees: captcha tests now harder than college entrance exams\n"
     ]
    }
   ],
   "source": [
    "_ = fit_patterns(fake_headlines, patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these four patterns alone account for more than a third of the fake dataset generated by ChatGPT!\n",
    "The recall on the sarcastic class is about four times, and the precision is also much more!\n",
    "\n",
    "Now let's do the same for some patterns for HuffPost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns =  [\n",
    "    \".*why.*\",\n",
    "    \".*how.*\",\n",
    "    \".*here's.*\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class = 0: precision=0.7516339869281046, recall=0.10281627179257935\n",
      "-- examples that fit these patterns: \n",
      "why trevor noah thinks hillary clinton will never connect with people\n",
      "newly sworn-in north korean official wondering how he'll eventually be executed\n",
      "why and how to eliminate mortgage charges by third parties\n",
      "you won't believe why this man's license was suspended\n",
      "the history of how salt and pepper became the world's most popular pairing\n",
      "dwight howard responds to lebron james' full-court shot with one of his own\n",
      "why did the dying grandma shred $1 million?\n",
      "upper-middle-class woman worries there's better coffee she doesn't know about\n",
      "grandfather seems proud of how many people polio killed\n",
      "this chinese video ​explains​ why beijing rejects the south china sea ruling\n"
     ]
    }
   ],
   "source": [
    "_ = fit_patterns(test_headlines, patterns, label=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class = 0: precision=0.8615384615384616, recall=0.4392156862745098\n",
      "-- examples that fit these patterns: \n",
      "how a group of friends turned a hobby into a successful side hustle\n",
      "why more doctors are saying you should skip the diet and focus on this\n",
      "why scientists are warning about a major arctic meltdown by 2030\n",
      "why co-living spaces are the future of affordable housing\n",
      "how tiktok changed the way we discover music forever\n",
      "why this indie actor is suddenly a household name\n",
      "how the latest election results are shaking up the senate\n",
      "why gen z is rejecting traditional career paths in droves\n",
      "how a pet chicken became a small town’s mascot\n",
      "why more people are turning to forest therapy for mental health\n"
     ]
    }
   ],
   "source": [
    "_ = fit_patterns(fake_headlines, patterns, label=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so the same can be seen for the non-sarcastic class.\n",
    "These three very simple patterns account for more than 40 percent of fake headlines by ChatGPT, whereas in the original dataset they were about 10 percent, and with noticeably less precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, one can conclude that ChatGPT is reinforcing the sterotypes and styles regarding the headlines of these two sources, by using their common patterns even more than they do.\n",
    "On the other hand, one can simultaneously conclude that these were the easier patterns to detect, and that ChatGPT has a lot of room for improvement in terms of covering all the styles, not just the more common and easier ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
