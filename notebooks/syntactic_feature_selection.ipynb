{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>syntax_tree</th>\n",
       "      <th>ratio_func_words</th>\n",
       "      <th>ratio_unique_pos</th>\n",
       "      <th>length</th>\n",
       "      <th>pos_repetitions</th>\n",
       "      <th>ratio_noun</th>\n",
       "      <th>ratio_verb</th>\n",
       "      <th>ratio_adj</th>\n",
       "      <th>ratio_adv</th>\n",
       "      <th>ratio_pron</th>\n",
       "      <th>ratio_propn</th>\n",
       "      <th>syntactic_depth</th>\n",
       "      <th>branching_factor</th>\n",
       "      <th>reversed_probability</th>\n",
       "      <th>average_surprisingness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>[{'text': 'thirtysomething', 'pos': 'ADJ', 'de...</td>\n",
       "      <td>[{'text': 'thirtysomething', 'dep': 'amod', 'c...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.922017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>[{'text': 'dem', 'pos': 'PROPN', 'dep': 'intj'...</td>\n",
       "      <td>[{'text': 'dem', 'dep': 'intj', 'children': []...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>6</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.849506</td>\n",
       "      <td>0.977015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>[{'text': 'eat', 'pos': 'VERB', 'dep': 'ROOT',...</td>\n",
       "      <td>[{'text': 'eat', 'dep': 'ROOT', 'children': ['...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>[{'text': 'inclement', 'pos': 'NOUN', 'dep': '...</td>\n",
       "      <td>[{'text': 'inclement', 'dep': 'compound', 'chi...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.805611</td>\n",
       "      <td>0.961821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>[{'text': 'mother', 'pos': 'NOUN', 'dep': 'nsu...</td>\n",
       "      <td>[{'text': 'mother', 'dep': 'nsubj', 'children'...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>0.873509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [{'text': 'thirtysomething', 'pos': 'ADJ', 'de...   \n",
       "1  [{'text': 'dem', 'pos': 'PROPN', 'dep': 'intj'...   \n",
       "2  [{'text': 'eat', 'pos': 'VERB', 'dep': 'ROOT',...   \n",
       "3  [{'text': 'inclement', 'pos': 'NOUN', 'dep': '...   \n",
       "4  [{'text': 'mother', 'pos': 'NOUN', 'dep': 'nsu...   \n",
       "\n",
       "                                         syntax_tree  ratio_func_words  \\\n",
       "0  [{'text': 'thirtysomething', 'dep': 'amod', 'c...          0.125000   \n",
       "1  [{'text': 'dem', 'dep': 'intj', 'children': []...          0.266667   \n",
       "2  [{'text': 'eat', 'dep': 'ROOT', 'children': ['...          0.125000   \n",
       "3  [{'text': 'inclement', 'dep': 'compound', 'chi...          0.250000   \n",
       "4  [{'text': 'mother', 'dep': 'nsubj', 'children'...          0.272727   \n",
       "\n",
       "   ratio_unique_pos  length  pos_repetitions  ratio_noun  ratio_verb  \\\n",
       "0          0.625000       8                1    0.500000    0.125000   \n",
       "1          0.600000      15                1    0.133333    0.133333   \n",
       "2          0.875000       8                0    0.250000    0.125000   \n",
       "3          0.500000       8                1    0.375000    0.375000   \n",
       "4          0.454545      11                1    0.181818    0.272727   \n",
       "\n",
       "   ratio_adj  ratio_adv  ratio_pron  ratio_propn  syntactic_depth  \\\n",
       "0   0.125000   0.000000       0.000     0.125000                5   \n",
       "1   0.133333   0.066667       0.000     0.266667                6   \n",
       "2   0.125000   0.125000       0.125     0.000000                4   \n",
       "3   0.000000   0.000000       0.000     0.000000                6   \n",
       "4   0.000000   0.272727       0.000     0.000000                6   \n",
       "\n",
       "   branching_factor  reversed_probability  average_surprisingness  \n",
       "0          1.400000              0.289101                0.922017  \n",
       "1          2.800000              0.849506                0.977015  \n",
       "2          1.750000              0.135305                0.887056  \n",
       "3          1.166667              0.805611                0.961821  \n",
       "4          2.000000              0.458575                0.873509  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   is_sarcastic            28619 non-null  int64  \n",
      " 1   headline                28619 non-null  object \n",
      " 2   pos_tags                28619 non-null  object \n",
      " 3   syntax_tree             28619 non-null  object \n",
      " 4   ratio_func_words        28619 non-null  float64\n",
      " 5   ratio_unique_pos        28619 non-null  float64\n",
      " 6   length                  28619 non-null  int64  \n",
      " 7   pos_repetitions         28619 non-null  int64  \n",
      " 8   ratio_noun              28619 non-null  float64\n",
      " 9   ratio_verb              28619 non-null  float64\n",
      " 10  ratio_adj               28619 non-null  float64\n",
      " 11  ratio_adv               28619 non-null  float64\n",
      " 12  ratio_pron              28619 non-null  float64\n",
      " 13  ratio_propn             28619 non-null  float64\n",
      " 14  syntactic_depth         28619 non-null  int64  \n",
      " 15  branching_factor        28619 non-null  float64\n",
      " 16  reversed_probability    28619 non-null  float64\n",
      " 17  average_surprisingness  28619 non-null  float64\n",
      "dtypes: float64(11), int64(4), object(3)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Path to the JSON file\n",
    "file_path = r\"C:\\Users\\MSC\\OneDrive - Fraunhofer Austria Research GmbH\\Desktop\\NLP\\data\\trans_prob_temp.csv\"\n",
    "\n",
    "# Reading the JSON file into a DataFrame\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()  # Display the first few rows of the DataFrame\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "display(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_sarcastic', 'headline', 'pos_tags', 'syntax_tree', 'ratio_func_words', 'ratio_unique_pos', 'length', 'pos_repetitions', 'ratio_noun', 'ratio_verb', 'ratio_adj', 'ratio_adv', 'ratio_pron', 'ratio_propn', 'syntactic_depth', 'branching_factor', 'reversed_probability', 'average_surprisingness']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_unique_pos</th>\n",
       "      <th>length</th>\n",
       "      <th>pos_repetitions</th>\n",
       "      <th>ratio_noun</th>\n",
       "      <th>ratio_verb</th>\n",
       "      <th>ratio_adj</th>\n",
       "      <th>ratio_adv</th>\n",
       "      <th>ratio_pron</th>\n",
       "      <th>ratio_propn</th>\n",
       "      <th>syntactic_depth</th>\n",
       "      <th>branching_factor</th>\n",
       "      <th>reversed_probability</th>\n",
       "      <th>average_surprisingness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.922017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>6</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.849506</td>\n",
       "      <td>0.977015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.805611</td>\n",
       "      <td>0.961821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>0.873509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio_unique_pos  length  pos_repetitions  ratio_noun  ratio_verb  \\\n",
       "0          0.625000       8                1    0.500000    0.125000   \n",
       "1          0.600000      15                1    0.133333    0.133333   \n",
       "2          0.875000       8                0    0.250000    0.125000   \n",
       "3          0.500000       8                1    0.375000    0.375000   \n",
       "4          0.454545      11                1    0.181818    0.272727   \n",
       "\n",
       "   ratio_adj  ratio_adv  ratio_pron  ratio_propn  syntactic_depth  \\\n",
       "0   0.125000   0.000000       0.000     0.125000                5   \n",
       "1   0.133333   0.066667       0.000     0.266667                6   \n",
       "2   0.125000   0.125000       0.125     0.000000                4   \n",
       "3   0.000000   0.000000       0.000     0.000000                6   \n",
       "4   0.000000   0.272727       0.000     0.000000                6   \n",
       "\n",
       "   branching_factor  reversed_probability  average_surprisingness  \n",
       "0          1.400000              0.289101                0.922017  \n",
       "1          2.800000              0.849506                0.977015  \n",
       "2          1.750000              0.135305                0.887056  \n",
       "3          1.166667              0.805611                0.961821  \n",
       "4          2.000000              0.458575                0.873509  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load your data (replace `data` with your actual DataFrame)\n",
    "# Assuming 'data' is already loaded and looks like the provided structure.\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = data.drop(columns=['pos_tags', 'syntax_tree'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.iloc[:, 3:]  # Columns 4-17\n",
    "y = data['is_sarcastic']\n",
    "\n",
    "# Initialize a dictionary to store feature importance scores\n",
    "feature_scores = {}\n",
    "\n",
    "display(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores:\n",
      "                         ANOVA_F       RFE  RandomForest  Average_Score\n",
      "ratio_verb              1.000000  1.000000      0.619594       0.873198\n",
      "ratio_unique_pos        0.655548  1.000000      0.536356       0.730634\n",
      "ratio_noun              0.526055  1.000000      0.500238       0.675431\n",
      "ratio_adv               0.496160  1.000000      0.262436       0.586199\n",
      "ratio_adj               0.187332  1.000000      0.358383       0.515238\n",
      "branching_factor        0.761033  0.156250      0.518813       0.478699\n",
      "average_surprisingness  0.062645  0.250000      1.000000       0.437548\n",
      "reversed_probability    0.000000  0.100000      0.979131       0.359710\n",
      "syntactic_depth         0.513614  0.035714      0.281690       0.277006\n",
      "ratio_pron              0.255375  0.437500      0.135734       0.276203\n",
      "ratio_propn             0.262081  0.062500      0.354240       0.226274\n",
      "length                  0.021638  0.000000      0.199567       0.073735\n",
      "pos_repetitions         0.015240  0.015625      0.000000       0.010288\n",
      "Selected Features: ['ratio_verb', 'ratio_unique_pos', 'ratio_noun', 'ratio_adv', 'ratio_adj', 'branching_factor', 'average_surprisingness', 'reversed_probability', 'syntactic_depth', 'ratio_pron', 'ratio_propn', 'length']\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter Method: Univariate Statistical Test (ANOVA F-test)\n",
    "select_k_best = SelectKBest(score_func=f_classif, k='all')\n",
    "anova_scores = select_k_best.fit(X, y).scores_\n",
    "\n",
    "# 2. Wrapper Method: Recursive Feature Elimination (RFE) with Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=log_model, n_features_to_select=5)  # Select top 5 features\n",
    "rfe.fit(X, y)\n",
    "rfe_ranks = rfe.ranking_\n",
    "\n",
    "# 3. Embedded Method: Feature Importance from Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X, y)\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale each method's scores to [0, 1]\n",
    "anova_scaled = scaler.fit_transform(anova_scores.reshape(-1, 1)).flatten()\n",
    "rfe_scaled = scaler.fit_transform((1 / rfe_ranks).reshape(-1, 1)).flatten()  # Inverse for ranking\n",
    "rf_scaled = scaler.fit_transform(rf_importances.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Combine the scores into a DataFrame\n",
    "feature_scores = {\n",
    "    'ANOVA_F': anova_scaled,\n",
    "    'RFE': rfe_scaled,\n",
    "    'RandomForest': rf_scaled\n",
    "}\n",
    "importance_df = pd.DataFrame(feature_scores, index=X.columns)\n",
    "\n",
    "# Add an average score column\n",
    "importance_df['Average_Score'] = importance_df.mean(axis=1)\n",
    "importance_df = importance_df.sort_values(by='Average_Score', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Scores:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Select features based on average score threshold\n",
    "selected_features = importance_df[importance_df['Average_Score'] > 0.05].index.tolist()\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# # Keep only selected features\n",
    "# X_selected = X[selected_features]\n",
    "\n",
    "# # Updated dataset with selected features and headlines\n",
    "# data_transformed = pd.concat([data[['is_sarcastic', 'headline']], X_selected], axis=1)\n",
    "# print(\"Transformed DataFrame:\")\n",
    "# print(data_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores:\n",
      "                         ANOVA_F  RFE  RandomForest  Average_Score\n",
      "length                  0.021638    9      0.045433       3.022357\n",
      "pos_repetitions         0.015240    8      0.018865       2.678035\n",
      "syntactic_depth         0.513614    7      0.055389       2.523001\n",
      "ratio_propn             0.262081    6      0.065784       2.109288\n",
      "reversed_probability    0.000000    5      0.148160       1.716053\n",
      "branching_factor        0.761033    4      0.086825       1.615952\n",
      "average_surprisingness  0.062645    3      0.151010       1.071219\n",
      "ratio_pron              0.255375    2      0.036807       0.764061\n",
      "ratio_verb              1.000000    1      0.099849       0.699950\n",
      "ratio_unique_pos        0.655548    1      0.089075       0.581541\n",
      "ratio_noun              0.526055    1      0.083633       0.536563\n",
      "ratio_adv               0.496160    1      0.052452       0.516204\n",
      "ratio_adj               0.187332    1      0.066720       0.418017\n",
      "Selected Features: ['length', 'pos_repetitions', 'syntactic_depth', 'ratio_propn', 'reversed_probability', 'branching_factor', 'average_surprisingness', 'ratio_pron', 'ratio_verb', 'ratio_unique_pos', 'ratio_noun', 'ratio_adv', 'ratio_adj']\n",
      "Transformed DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>length</th>\n",
       "      <th>pos_repetitions</th>\n",
       "      <th>syntactic_depth</th>\n",
       "      <th>ratio_propn</th>\n",
       "      <th>reversed_probability</th>\n",
       "      <th>branching_factor</th>\n",
       "      <th>average_surprisingness</th>\n",
       "      <th>ratio_pron</th>\n",
       "      <th>ratio_verb</th>\n",
       "      <th>ratio_unique_pos</th>\n",
       "      <th>ratio_noun</th>\n",
       "      <th>ratio_adv</th>\n",
       "      <th>ratio_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.922017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.849506</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.887056</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805611</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.961821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.873509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  length  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...       8   \n",
       "1             0  dem rep. totally nails why congress is falling...      15   \n",
       "2             0  eat your veggies: 9 deliciously different recipes       8   \n",
       "3             1  inclement weather prevents liar from getting t...       8   \n",
       "4             1  mother comes pretty close to using word 'strea...      11   \n",
       "\n",
       "   pos_repetitions  syntactic_depth  ratio_propn  reversed_probability  \\\n",
       "0                1                5     0.125000              0.289101   \n",
       "1                1                6     0.266667              0.849506   \n",
       "2                0                4     0.000000              0.135305   \n",
       "3                1                6     0.000000              0.805611   \n",
       "4                1                6     0.000000              0.458575   \n",
       "\n",
       "   branching_factor  average_surprisingness  ratio_pron  ratio_verb  \\\n",
       "0          1.400000                0.922017       0.000    0.125000   \n",
       "1          2.800000                0.977015       0.000    0.133333   \n",
       "2          1.750000                0.887056       0.125    0.125000   \n",
       "3          1.166667                0.961821       0.000    0.375000   \n",
       "4          2.000000                0.873509       0.000    0.272727   \n",
       "\n",
       "   ratio_unique_pos  ratio_noun  ratio_adv  ratio_adj  \n",
       "0          0.625000    0.500000   0.000000   0.125000  \n",
       "1          0.600000    0.133333   0.066667   0.133333  \n",
       "2          0.875000    0.250000   0.125000   0.125000  \n",
       "3          0.500000    0.375000   0.000000   0.000000  \n",
       "4          0.454545    0.181818   0.272727   0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Wrapper Method: Recursive Feature Elimination (RFE) with Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=log_model, n_features_to_select=5)  # Select top 5 features\n",
    "rfe.fit(X, y)\n",
    "feature_scores['RFE'] = rfe.ranking_\n",
    "\n",
    "# 3. Embedded Method: Feature Importance from Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X, y)\n",
    "feature_scores['RandomForest'] = rf_model.feature_importances_\n",
    "\n",
    "# Combine results into a DataFrame for comparison\n",
    "importance_df = pd.DataFrame(feature_scores, index=X.columns)\n",
    "importance_df['Average_Score'] = importance_df.mean(axis=1)\n",
    "importance_df = importance_df.sort_values(by='Average_Score', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Scores:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Select features based on average score threshold\n",
    "selected_features = importance_df[importance_df['Average_Score'] > 0.05].index.tolist()\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Keep only selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Updated dataset with selected features and headlines\n",
    "data_transformed = pd.concat([data[['is_sarcastic', 'headline']], X_selected], axis=1)\n",
    "print(\"Transformed DataFrame:\")\n",
    "display(data_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "SEED = 42\n",
    "train_headlines, other_headlines = split(data, test_size=0.3, random_state=SEED)  # 70% training\n",
    "val_headlines, test_headlines = split(other_headlines, test_size=0.5, random_state=SEED)  # 15% validation, 15% test\n",
    "\n",
    "# Prepare data for the Logistic Regression model\n",
    "# Extract the corresponding feature values for train, validation, and test\n",
    "X_train = X.loc[train_headlines.index]\n",
    "y_train = y.loc[train_headlines.index]\n",
    "X_val = X.loc[val_headlines.index]\n",
    "y_val = y.loc[val_headlines.index]\n",
    "X_test = X.loc[test_headlines.index]\n",
    "y_test = y.loc[test_headlines.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratio_verb', 'ratio_unique_pos', 'ratio_noun', 'ratio_adv', 'ratio_adj']\n",
      "Confusion Matrix:\n",
      "[[1632  605]\n",
      " [ 747 1309]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      2237\n",
      "           1       0.68      0.64      0.66      2056\n",
      "\n",
      "    accuracy                           0.69      4293\n",
      "   macro avg       0.68      0.68      0.68      4293\n",
      "weighted avg       0.68      0.69      0.68      4293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the 5 best features from RFE scores\n",
    "top_5_features = importance_df.sort_values(by='RFE').head(5).index.tolist()\n",
    "print(top_5_features)\n",
    "\n",
    "# Use only the top 5 features for training and testing\n",
    "X_train_top5 = X_train[top_5_features]\n",
    "X_test_top5 = X_test[top_5_features]\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "log_model.fit(X_train_top5, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_model.predict(X_test_top5)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['average_surprisingness', 'reversed_probability', 'ratio_verb', 'ratio_unique_pos', 'branching_factor']\n",
      "Confusion Matrix (Random Forest):\n",
      "[[1445  792]\n",
      " [ 809 1247]]\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      2237\n",
      "           1       0.61      0.61      0.61      2056\n",
      "\n",
      "    accuracy                           0.63      4293\n",
      "   macro avg       0.63      0.63      0.63      4293\n",
      "weighted avg       0.63      0.63      0.63      4293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the 5 best features from Random Forest importance scores\n",
    "top_5_rf_features = importance_df.sort_values(by='RandomForest', ascending=False).head(5).index.tolist()\n",
    "print(top_5_rf_features)\n",
    "\n",
    "# Use only the top 5 features for training and testing\n",
    "X_train_top5_rf = X_train[top_5_rf_features]\n",
    "X_test_top5_rf = X_test[top_5_rf_features]\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=SEED)\n",
    "rf_model.fit(X_train_top5_rf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_top5_rf)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix (Random Forest):\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratio_verb', 'ratio_unique_pos', 'ratio_noun', 'ratio_adv', 'ratio_adj', 'headline']\n"
     ]
    }
   ],
   "source": [
    "# Path to the JSON file\n",
    "file_path = r\"C:\\Users\\MSC\\OneDrive - Fraunhofer Austria Research GmbH\\Desktop\\NLP\\data\\trans_prob_temp.csv\"\n",
    "\n",
    "# Reading the JSON file into a DataFrame\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()  # Display the first few rows of the DataFrame\n",
    "\n",
    "top_5_features.append('headline')\n",
    "print(top_5_features)\n",
    "X = data[top_5_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_verb</th>\n",
       "      <th>ratio_unique_pos</th>\n",
       "      <th>ratio_noun</th>\n",
       "      <th>ratio_adv</th>\n",
       "      <th>ratio_adj</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio_verb  ratio_unique_pos  ratio_noun  ratio_adv  ratio_adj  \\\n",
       "0    0.125000          0.625000    0.500000   0.000000   0.125000   \n",
       "1    0.133333          0.600000    0.133333   0.066667   0.133333   \n",
       "2    0.125000          0.875000    0.250000   0.125000   0.125000   \n",
       "3    0.375000          0.500000    0.375000   0.000000   0.000000   \n",
       "4    0.272727          0.454545    0.181818   0.272727   0.000000   \n",
       "\n",
       "                                            headline  \n",
       "0  thirtysomething scientists unveil doomsday clo...  \n",
       "1  dem rep. totally nails why congress is falling...  \n",
       "2  eat your veggies: 9 deliciously different recipes  \n",
       "3  inclement weather prevents liar from getting t...  \n",
       "4  mother comes pretty close to using word 'strea...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
